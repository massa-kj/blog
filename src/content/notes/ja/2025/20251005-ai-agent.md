---
title: "AI エージェントの仕組みと構成要素"
date: "2025-10-05"
tags: ["ai", "agent", "llm", "mcp", "rag"]
summary: "LLM を中核とした AI エージェントの仕組み、構成要素、処理フローについて整理"
---

## LLM を使った AI エージェントの仕組み

- 開発における AI 活用
  - 業務で AI エージェントを利用してみて、使い方次第で生産性、学習効率ともに大きく向上していることを実感。
  - 部分的なコーディング技術の優位性は下がっていくと思われる。
  - 今後開発においても、AI 活用は前提になる。AI をどう活用するか、AI エージェントの構造理解によって、エンジニアとしての能力や成長は大きく変わってくる。
- AI エージェントとは
  - ChatGPT や GitHub Copilot は AI エージェント。LLM を中核に据え、ユーザーの入力を解析し、必要に応じて外部ツールや知識を利用してタスクを遂行する。
  - AI エージェントの基本的な処理の流れは、ユーザーからの入力に対して、LLM、RAG、MCP 等を利用して出力を生成、あるいはタスクを処理する。
  - AI エージェントの差異は、モデル選択、RAG やキャッシュの持ち方や利用の仕方、MCP 活用、LLM の使いどころによって大きく変わる。
- AI エージェントの構成要素例
  ```mermaid
  flowchart TD
    subgraph Orchestrator["🎯 エージェント / クライアント（オーケストレーター）"]
      Planner["🗂️ Planner（制御・段取り）"]
      Memory["🧾 Memory（文脈・状態保持）"]
      LLM["🧠 LLM（思考・判断・生成）"]
    end
  
    subgraph External["📡 外部拡張レイヤー"]
      RAG["📚 RAG（知識検索機能）"]
      MCP["🛠 MCP（ツール呼び出しプロトコル）"]
    end
  
    User["🧑 ユーザー入力"]
    Output["🗣 応答 / 実行結果"]
  
    User --> Planner
    Planner --> LLM
    LLM -->|出力| Planner
  
    Planner -->|必要に応じて| RAG
    Planner -->|必要に応じて| MCP
    RAG --> Planner
    MCP --> Planner
  
    Planner <--> Memory
    LLM <--> Memory
  
    Planner --> Output
  ```
  - オーケストレーター（エージェント / クライアント）
    | 要素                  | 主な責務                                                    | 入力                              | 出力                         | 補足                        |
    | ------------------- | ------------------------------------------------------- | ------------------------------- | -------------------------- | ------------------------- |
    | Planner（制御・段取り） | ユーザー意図を解析し、どの手順でどのツールを使うかを決定する。LLMを利用した思考やツール呼び出しを統制する。 | ユーザー入力、Memoryの状態、LLM出力          | 実行計画、LLM呼び出し指示、RAG/MCP呼び出し | 「頭脳の司令塔」。Agentの中核ロジック。    |
    | LLM（思考・判断・生成）   | 推論・要約・説明・判断などを行い、テキストを生成する。                             | Plannerからのプロンプト、Memory/RAGからの知識 | テキスト応答、ツール呼び出し提案           | 「思考エンジン」。場合によっては自律的提案も可能。 |
    | Memory（文脈・状態保持） | 過去の会話・実行状態・中間結果などを保持し、必要に応じてPlannerやLLMに提供する。           | Planner/LLMからの書き込み要求            | 保存済みの文脈情報                  | 「短期記憶」や「作業メモ」。RAGとは異なり動的。 |
  
  - 外部拡張レイヤー
    | 要素               | 主な責務                                 | 入力                 | 出力             | 補足                  |
    | ---------------- | ------------------------------------ | ------------------ | -------------- | ------------------- |
    | RAG（知識検索）    | ローカルや外部DBから関連知識を検索し、LLMの生成を支援する。     | クエリ（LLM/Planner生成） | 関連ドキュメント、抜粋、要約 | 「長期記憶」に相当。静的な知識ベース。 |
    | MCP（ツール呼び出し） | コマンド実行・API呼び出し・外部サービス連携などを抽象化して提供する。 | 実行命令（Planner発）     | 実行結果、エラーメッセージ  | 「行動の腕」。世界との接点。      |
  
  - 補足概念
    | 概念                  | 概要                             | 例                          |
    | ------------------- | ------------------------------ | -------------------------- |
    | User（入力）        | 自然言語または構造化指令を入力。               | 「S3バケット一覧を出して」             |
    | Output（応答）      | エージェントの最終出力。実行結果や要約など。         | 「以下がS3バケット一覧です…」           |
    | Context Flow    | Planner ⇄ LLM ⇄ Memory 間での文脈共有 | 「過去の質問との関連付け」「前回の出力を再利用」など |
    | Tool Invocation | Planner ⇄ MCP または RAG 呼び出し     | 「API呼び出し」「ファイル検索」など        |
  
  - 処理フロー（概略）
    1. User入力受信 → Plannerが意図を解析
    2. Planner が「LLMに考えさせる」「RAGで検索する」「MCPで実行する」などを判断
    3. LLM が思考・生成を行い、Plannerに返す
    4. Planner が必要に応じて外部ツール呼び出し
    5. Memory に会話や状態を保存（次回以降の文脈維持）
    6. 最終出力（Output） をユーザーに返却

- LLM の役割と限界
  - LLM 単体はあくまでテキスト生成するモデル。実際の環境操作やタスク実行はできない。
  - しかし、LLM は RAG や MCP ツールを利用すべきかどうかの判断に利用できる（Function Calling / Tool Use機能）。
  - エージェント処理の中でも LLM にコマンドの生成、選択の判断、要約を行ってもらう。
  - 最新のモデル（GPT-4、Claude 3.5 Sonnet など）は、構造化された出力（JSON形式など）の生成も得意。

- MCP（Model Context Protocol）の活用
  - 基本概念: Anthropic が開発したプロトコルで、AI モデルが外部ツールやリソースと安全に連携するための標準規格。
  - 機能拡張: MCP により、LLM を使った AI エージェントが実際のタスク処理（ファイル操作、API呼び出し、データベースアクセスなど）を実行可能になる。
  - セキュリティ: サンドボックス化されたツール実行環境により、安全な外部システム連携を実現。
  - 実装例:
    - ChatGPT や GitHub Copilot からも MCP サーバーを利用できる
    - 自前で MCP サーバーを構築してカスタムツールとして利用可能
    - VS Code の場合、`settings.json` の記述により MCP サーバープログラムの起動から管理
      - LSP（Language Server Protocol）と同様、標準入出力を利用した軽量な通信方式
  - 活用例: ファイルシステム操作、Git操作、データベースクエリ、Web API呼び出し、コード実行など

- RAG（Retrieval-Augmented Generation）の詳細
  - 概念: 検索拡張生成。LLM の生成能力と外部知識の検索を組み合わせる手法。
  - 処理手順:
    1. インデックス化: ドキュメントをベクトル化してデータベースに保存
    2. 検索: ユーザークエリに類似するドキュメントを検索
    3. 生成: 検索結果を文脈として LLM に与えて回答生成
  - 技術要素:
    - Embedding Model: テキストをベクトル表現に変換（OpenAI text-embedding-ada-002, Sentence Transformers など）
    - Vector Database: 高速な類似度検索を可能にする（Pinecone, Weaviate, Chroma など）
    - Chunking Strategy: 長文書を適切なサイズに分割する手法
  - メリット: 最新情報の反映、専門知識の活用、ハルシネーション（幻覚）の抑制

## 実際の AI エージェント事例

- 開発支援系:
  - GitHub Copilot: コード補完、MCP によるファイル操作、Git統合
  - Cursor: コードベース全体の理解、RAG による関連コード検索
  - v0.dev (Vercel): UI コンポーネント生成、プレビュー機能との連携

- 汎用系:
  - ChatGPT: Code Interpreter、プラグインシステム、画像解析
  - Claude: Artifacts機能、MCP サーバー連携
  - Google Bard/Gemini: Google Workspace 連携、リアルタイム情報検索

- 特化型:
  - Devin: 完全自律的なソフトウェアエンジニア AI エージェント
  - AutoGPT: 目標設定から実行まで自律的に処理
  - LangChain Agents: カスタマイズ可能なエージェントフレームワーク

## 未調査

- LLM 以外の AI エージェント開発 最前線
- プロンプトエンジニアリングの重要性
- AI エージェントの評価・測定方法
- セキュリティとプライバシーの考慮事項
- コスト最適化の戦略
